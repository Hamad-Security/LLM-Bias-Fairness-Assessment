{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26f4dea5",
   "metadata": {},
   "source": [
    "# Deep Evaluation of LLM-Based Recommender Systems (with Auto-Save Plots)\n",
    "*Generated 2025-05-06 09:20 UTC*\n",
    "\n",
    "This notebook computes in-depth accuracy, popularity bias, and fairness metrics, and automatically saves all plots to the `analysisresults/` folder using a context manager."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba452a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from contextlib import contextmanager\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "@contextmanager\n",
    "def autosave_fig(name, folder=\"analysisresults\", dpi=300, fmt=\"png\"):\n",
    "    path = Path(folder)\n",
    "    path.mkdir(parents=True, exist_ok=True)\n",
    "    try:\n",
    "        yield\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(path / f\"{name}.{fmt}\", dpi=dpi)\n",
    "    finally:\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f92ab4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import re\n",
    "\n",
    "STRATEGY_OPTS  = [\"random\", \"top-rated\", \"recent\"]\n",
    "FAIRNESS_OPTS  = [\"neutral\", \"gender_age_only\", \"occupation_only\", \"all_attributes\"]\n",
    "BIAS_OPTS      = [\"baseline\", \"niche_genre\", \"exclude_popular\", \"indie_international\", \"temporal_diverse\", \"obscure_theme\"]\n",
    "\n",
    "PROMPT_RE = re.compile(\n",
    "    r'^(?P<user>\\d+)'\n",
    "    r'_(?P<strategy>' + \"|\".join(STRATEGY_OPTS) + r')'\n",
    "    r'_(?P<fairness>' + \"|\".join(FAIRNESS_OPTS) + r')'\n",
    "    r'_(?P<bias>' + \"|\".join(BIAS_OPTS) + r')$'\n",
    ")\n",
    "\n",
    "def parse_prompt_id(pid: str):\n",
    "    m = PROMPT_RE.match(pid)\n",
    "    if not m:\n",
    "        raise ValueError(f\"Bad prompt_id: {pid}\")\n",
    "    d = m.groupdict()\n",
    "    d[\"user\"] = int(d[\"user\"])\n",
    "    return d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f0167c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd, numpy as np, math, collections, itertools\n",
    "import matplotlib.pyplot as plt, seaborn as sns\n",
    "from rapidfuzz import process, fuzz\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (8,5)\n",
    "\n",
    "# File paths\n",
    "USER_DATA_PATH = '../Dataset/full_movies_data.csv'\n",
    "RECS_PATH      = '../LlmCsvOutput/merged_prompt_results_top_rated.csv'\n",
    "\n",
    "# Load data\n",
    "user_df = pd.read_csv(USER_DATA_PATH)\n",
    "rec_df  = pd.read_csv(RECS_PATH).rename(columns={'custom_id':'prompt_id'})\n",
    "rec_df['movies'] = rec_df['movies'].str.split(',').apply(lambda lst: [m.strip() for m in lst])\n",
    "rec_df = pd.concat([rec_df['prompt_id'].apply(parse_prompt_id).apply(pd.Series), rec_df], axis=1)\n",
    "\n",
    "# Popularity and liked movie dicts\n",
    "popularity_counts = user_df['Title'].value_counts()\n",
    "title_to_rank     = {t: r for r, t in enumerate(popularity_counts.index, 1)}\n",
    "user_likes        = user_df[user_df['Rating'] > 2].groupby('UserID')['Title'].apply(set).to_dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be9e046",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fuzzy_hits(recs, liked, cutoff=80):\n",
    "    return sum(1 for rec in recs if process.extractOne(rec, liked, scorer=fuzz.token_sort_ratio, score_cutoff=cutoff))\n",
    "\n",
    "def precision_at_k(recs, liked, k): return fuzzy_hits(recs[:k], liked) / k if k else 0\n",
    "def recall_at_k(recs, liked, k):    return fuzzy_hits(recs[:k], liked) / len(liked) if liked else 0\n",
    "\n",
    "def ndcg_at_k(recs, liked, k):\n",
    "    dcg = sum((1 / math.log2(i+2)) for i, itm in enumerate(recs[:k]) if itm in liked)\n",
    "    ideal = sum(1 / math.log2(i+2) for i in range(min(k, len(liked))))\n",
    "    return dcg / ideal if ideal else 0\n",
    "\n",
    "def apk(recs, liked, k):\n",
    "    score = hits = 0\n",
    "    for i, itm in enumerate(recs[:k], 1):\n",
    "        if itm in liked:\n",
    "            hits += 1\n",
    "            score += hits / i\n",
    "    return score / min(len(liked), k) if liked else 0\n",
    "\n",
    "def rr(recs, liked):\n",
    "    for i, itm in enumerate(recs, 1):\n",
    "        if itm in liked:\n",
    "            return 1/i\n",
    "    return 0\n",
    "\n",
    "def avg_pop_rank(recs): return np.mean([title_to_rank.get(m, len(title_to_rank)+1) for m in recs]) if recs else np.nan\n",
    "\n",
    "def log_pop_diff(recs, hist):\n",
    "    rec_pop  = [math.log(popularity_counts.get(m,1)) for m in recs]\n",
    "    hist_pop = [math.log(popularity_counts.get(m,1)) for m in hist]\n",
    "    return np.mean(rec_pop) - np.mean(hist_pop) if rec_pop and hist_pop else 0\n",
    "\n",
    "def is_long_tail(title, cutoff=int(len(title_to_rank)*0.8)):\n",
    "    return title_to_rank.get(title, cutoff+1) > cutoff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dae6699",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "user_hist_cache = {}\n",
    "records = []\n",
    "\n",
    "for row in tqdm(rec_df.itertuples(index=False), total=len(rec_df), desc=\"Evaluating\"):\n",
    "    uid = row.user\n",
    "    if uid not in user_hist_cache:\n",
    "        user_hist_cache[uid] = user_df.loc[user_df['UserID'] == uid, 'Title'].tolist()\n",
    "    hist  = user_hist_cache[uid]\n",
    "    liked = user_likes.get(uid, set())\n",
    "    movies = row.movies\n",
    "\n",
    "    records.append({\n",
    "        \"prompt_id\"     : row.prompt_id,\n",
    "        \"strategy\"      : row.strategy,\n",
    "        \"fairness\"      : row.fairness,\n",
    "        \"bias\"          : row.bias,\n",
    "        \"precision@10\"  : precision_at_k(movies, liked, 10),\n",
    "        \"recall@10\"     : recall_at_k(movies, liked, 10),\n",
    "        \"ndcg@10\"       : ndcg_at_k(movies, liked, 10),\n",
    "        \"ap@10\"         : apk(movies, liked, 10),\n",
    "        \"rr\"            : rr(movies, liked),\n",
    "        \"avg_pop_rank\"  : avg_pop_rank(movies),\n",
    "        \"log_pop_diff\"  : log_pop_diff(movies, hist),\n",
    "        \"lt_coverage_pct\": sum(is_long_tail(t) for t in movies)/len(movies) if movies else np.nan\n",
    "    })\n",
    "\n",
    "metrics_df = pd.DataFrame(records)\n",
    "metrics_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc16b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "metrics_to_plot = [\n",
    "    (\"precision@10\",      \"Precision@10\"),\n",
    "    (\"recall@10\",         \"Recall@10\"),\n",
    "    (\"ndcg@10\",           \"NDCG@10\"),\n",
    "    (\"avg_pop_rank\",      \"Average popularity rank\"),\n",
    "    (\"log_pop_diff\",      \"Log-popularity difference\"),\n",
    "    (\"lt_coverage_pct\",   \"Long-tail coverage %\"),\n",
    "]\n",
    "\n",
    "bias_order = [\"baseline\", \"niche_genre\", \"exclude_popular\",\n",
    "              \"indie_international\", \"temporal_diverse\", \"obscure_theme\"]\n",
    "\n",
    "for col, label in metrics_to_plot:\n",
    "    with autosave_fig(f\"{col.replace('@','_at_')}_by_fairness_lines\"):\n",
    "        plt.figure(figsize=(9,5))\n",
    "        pivot = (\n",
    "            metrics_df\n",
    "            .groupby(['fairness','bias'])[col]\n",
    "            .mean()\n",
    "            .unstack('bias')\n",
    "            .reindex(columns=bias_order)\n",
    "        )\n",
    "        for fairness, yvals in pivot.iterrows():\n",
    "            plt.plot(bias_order, yvals, marker='o', label=fairness)\n",
    "\n",
    "        plt.title(f\"{label} across bias strategies by fairness group\")\n",
    "        plt.xlabel(\"Bias strategy\")\n",
    "        plt.ylabel(label)\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.grid(True, alpha=.3)\n",
    "        plt.legend(title=\"Fairness setting\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28970b23",
   "metadata": {},
   "source": [
    "Notebook complete. All charts auto-saved to `analysisresults/`. You may continue your analysis below."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
